import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from xgboost import XGBClassifier
import torch
import pandas as pd
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import GroupShuffleSplit, train_test_split
from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV
from sklearn.model_selection import GroupKFold
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns


class ReencodeXGB(XGBClassifier):
    """fit ë•Œ y ë¥¼ 0â€‘basedë¡œ ì¬ì¸ì½”ë”© â†’ ë¼ë²¨ ëˆ„ë½ì— ìƒê´€ì—†ì´ ë™ì‘"""
    def fit(self, X, y, **kw):
        self._le = LabelEncoder().fit(y)
        y_enc = self._le.transform(y)          # 0â€‘based
        return super().fit(X, y_enc, **kw)

    def predict(self, X):
        return self._le.inverse_transform(super().predict(X))

    def predict_proba(self, X):
        proba = super().predict_proba(X)
        # ì»¬ëŸ¼ ìˆ˜ê°€ self._le.classes_ ê¸¸ì´ì™€ ê°™ì§€ ì•Šìœ¼ë©´ íŒ¨ë”©
        if proba.shape[1] != len(self._le.classes_):
            full = np.zeros((proba.shape[0], len(self._le.classes_)))
            full[:, self._le.transform(self._le.classes_)] = proba
            proba = full
        return proba



def get_specificity(y_true, y_pred, n_classes):
        """
        í´ë˜ìŠ¤ë³„ Specificity = TN / (TN + FP) ê³„ì‚°
        ë°˜í™˜ shape: (n_classes,)
        """
        cm = confusion_matrix(y_true, y_pred, labels=np.arange(n_classes))
        tn = []
        fp = cm.sum(axis=0) - np.diag(cm)
        for k in range(n_classes):
            # ì „ì²´ í•© â€“ (í•´ë‹¹ í´ë˜ìŠ¤ í–‰í•© + í•´ë‹¹ í´ë˜ìŠ¤ ì—´í•© â€“ TP)
            tn_k = cm.sum() - (cm[k, :].sum() + cm[:, k].sum() - cm[k, k])
            tn.append(tn_k)
        tn = np.array(tn)
        return tn / (tn + fp + 1e-8)          # 0â€‘division ë°©ì§€ìš© eps

def print_full_report(y_true, y_pred, target_names):
    """
    í•˜ë‚˜ì˜ í‘œì— Sensitivity, Specificity, TP, FP, FN, TNì„ ëª¨ë‘ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    n_cls = len(target_names)
    
    # 1. classification_reportì—ì„œ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    rep = classification_report(
        y_true, y_pred, target_names=target_names, labels=np.arange(n_cls),
        output_dict=True, zero_division=0)
    df = pd.DataFrame(rep).T.iloc[:n_cls, :]
    
    # 2. Confusion Matrix ê¸°ë°˜ ê°’ë“¤ ê³„ì‚°
    cm = confusion_matrix(y_true, y_pred, labels=np.arange(n_cls))
    tp = np.diag(cm)
    fp = cm.sum(axis=0) - tp
    fn = cm.sum(axis=1) - tp
    tn = cm.sum() - (tp + fp + fn)
    
    # 3. DataFrameì— ìƒˆë¡œìš´ ì—´ ì¶”ê°€
    df['Sensitivity'] = df['recall'] # recall -> Sensitivity ì´ë¦„ ë³€ê²½
    df['Specificity'] = tn / (tn + fp + 1e-8)
    df['TP'] = tp
    df['FP'] = fp
    df['FN'] = fn
    df['TN'] = tn

    # 4. ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ ì§€ì • ë° ì¶œë ¥
    df = df[['Sensitivity', 'Specificity', 'TP', 'FP', 'FN', 'TN', 'support']]
    print(df.round(3))
# â”€â”€ 0. íŒŒì¼ ë¡œë“œ ë° ì„¤ì • (ìˆ˜ì •) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ORIGINAL_DATA_DIR = Path("mel_specs_augmented_aiu")
if not ORIGINAL_DATA_DIR.is_dir():
    ORIGINAL_DATA_DIR = Path("mel_specs aiu")

# í´ë˜ìŠ¤ ì´ë¦„ -> ë¼ë²¨ ì¸ë±ìŠ¤ ë§µ ìƒì„±
SUFFIXES_FOR_MAP = ["_a", "_i", "_u"]
class_names = sorted({d.name[:-len(sfx)] for d in ORIGINAL_DATA_DIR.iterdir() if d.is_dir() for sfx in SUFFIXES_FOR_MAP if d.name.endswith(sfx)})
label_map = {name: idx for idx, name in enumerate(class_names)}
print("ê°ì§€ëœ í´ë˜ìŠ¤:", label_map)


# â”€â”€ 1. í™˜ì ë‹¨ìœ„ ë¶„í•  ì •ë³´ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CNN í•™ìŠµ ì‹œ ì‚¬ìš©í–ˆë˜ í™˜ì ë¶„í•  ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
split_file = "patient_split_seed(agu).npz"
try:
    sp = np.load(split_file, allow_pickle=True)
    train_pids = set(sp["train"])
    val_pids   = set(sp["val"])
    test_pids  = set(sp["test"])
    print(f"âœ… CNNê³¼ ë™ì¼í•œ í™˜ì ë¶„í•  ì •ë³´ ë¡œë“œ ì™„ë£Œ: Train {len(train_pids)}, Val {len(val_pids)}, Test {len(test_pids)} ëª…")
except FileNotFoundError:
    print(f"[ì˜¤ë¥˜] í™˜ì ë¶„í•  íŒŒì¼ '{split_file}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. train_cnn.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ íŒŒì¼ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.")
    exit()

# êµì§‘í•© ê²€ì¦
assert train_pids.isdisjoint(val_pids) and train_pids.isdisjoint(test_pids) and val_pids.isdisjoint(test_pids)


# â”€â”€ 2. ëª¨ìŒë³„ ìŠ¤ì¼€ì¼ëŸ¬ + XGB(GridSearch) í•™ìŠµ (ë°ì´í„° ë¡œë”© ë¡œì§ í†µí•©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PARAM_GRID = {
    "n_estimators": [100, 200],
    "max_depth":    [5, 7],
    "learning_rate":[0.05, 0.1]
}
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

models, scalers = {}, {}
all_y_true = None  # ëª¨ë“  ëª¨ìŒì—ì„œ ë™ì¼í•œ test setì˜ y_trueë¥¼ ê³µìœ í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
all_probas = []    # ì†Œí”„íŠ¸ ë³´íŒ…ì„ ìœ„í•œ í™•ë¥  ì €ì¥ ë¦¬ìŠ¤íŠ¸

for sfx in ("a", "i", "u"):
    print(f"\n================ Processing Vowel: '{sfx}' ================")
    
    # 1. ê° ëª¨ìŒì— í•´ë‹¹í•˜ëŠ” í”¼ì²˜, ID, ë¼ë²¨ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        X = np.load(f"cnn_features_{sfx}.npy")
        ids = np.load(f"cnn_ids_{sfx}.npy")
        y = np.load(f"cnn_labels_{sfx}.npy")
    except FileNotFoundError:
        print(f"[ê²½ê³ ] '{sfx}'ì— ëŒ€í•œ í”¼ì²˜/ID/ë¼ë²¨ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆ<binary data, 2 bytes>ë‹ˆë‹¤.")
        continue

    # 2. í™˜ì ë¶„í•  ê¸°ì¤€(pids)ì„ ì´ìš©í•´ í˜„ì¬ ëª¨ìŒ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ ìƒì„±
    # ì´ ë°©ì‹ì€ 'a'ì—ë§Œ ìˆëŠ” ìƒ˜í”Œ, 'i'ì—ë§Œ ìˆëŠ” ìƒ˜í”Œ ë“±ì„ ëª¨ë‘ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    idx_tr = np.where(np.isin(ids, list(train_pids)))[0]
    idx_va = np.where(np.isin(ids, list(val_pids)))[0]
    idx_te = np.where(np.isin(ids, list(test_pids)))[0]

    print(f"ìƒ˜í”Œ ë¶„í• : Train {len(idx_tr)}, Val {len(idx_va)}, Test {len(idx_te)} ê°œ")
    
    # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ (ë””ë²„ê¹…ìš©)
    uniq, cnt = np.unique(y[idx_te], return_counts=True)
    print(f"Test set class distribution for '{sfx}': {dict(zip(uniq, cnt))}")

    # 3. ìŠ¤ì¼€ì¼ë§ ë° ëª¨ë¸ í•™ìŠµ (ê¸°ì¡´ ì½”ë“œì™€ ìœ ì‚¬)
    scaler = StandardScaler().fit(X[idx_tr])
    X_sc   = scaler.transform(X)

    xgb = ReencodeXGB(
        eval_metric="mlogloss",
        tree_method="hist",
        device=DEVICE,
        random_state=42
    )

    cv_splitter = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=42)
    gscv = GridSearchCV(
        estimator=xgb,
        param_grid=PARAM_GRID,
        cv=cv_splitter,
        scoring="accuracy",
        n_jobs=-1,
        error_score="raise"
    )
    gscv.fit(X_sc[idx_tr], y[idx_tr], groups=ids[idx_tr])

    best = gscv.best_estimator_
    val_acc = accuracy_score(y[idx_va], best.predict(X_sc[idx_va]))
    print(f"'{sfx}' best {gscv.best_params_} | val acc {val_acc:.3f}")

    models[sfx], scalers[sfx] = best, scaler
    
    # --- ë‹¨ì¼ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ---
    print(f"\n--- ë‹¨ì¼ ëª¨ë¸ '{sfx}' í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ---")
    y_pred_single = best.predict(X_sc[idx_te])
    y_true_single = y[idx_te]
    acc_single = accuracy_score(y_true_single, y_pred_single)
    print(f"Accuracy: {acc_single:.4f}")
    print_full_report(y_true_single, y_pred_single, list(label_map.keys()))

    # ì†Œí”„íŠ¸ ë³´íŒ…ì„ ìœ„í•´ test set ì˜ˆì¸¡ í™•ë¥  ì €ì¥
    # y_trueëŠ” ëª¨ë“  ëª¨ìŒì—ì„œ ë™ì¼í•´ì•¼ í•¨ (í™˜ì ë¶„í• ì´ ê°™ìœ¼ë¯€ë¡œ)
    if all_y_true is None:
        all_y_true = y[idx_te]
    
    # all_probas ë¦¬ìŠ¤íŠ¸ì— ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ ì¶”ê°€
    all_probas.append(best.predict_proba(X_sc[idx_te]))


# â”€â”€ 3. ì†Œí”„íŠ¸ ë³´íŒ…(í™•ë¥  í‰ê· ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# all_probasì— ì €ì¥ëœ ëª¨ë“  í™•ë¥ ì„ í•©ì‚°
proba_sum = np.sum(all_probas, axis=0) 
y_pred = proba_sum.argmax(axis=1)
print("\n\nğŸ“Š --- ìµœì¢… Soft-Voting Result ---")
print("Accuracy :", accuracy_score(all_y_true, y_pred))
print_full_report(all_y_true, y_pred, list(label_map.keys()))

